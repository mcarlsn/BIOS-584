{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW6 (20')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "    \n",
    "Please submit your assignment as an HTML or PDF file.\n",
    "\n",
    "Print your name (First and Last) below."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T15:10:04.707431Z",
     "start_time": "2025-10-03T15:10:04.704869Z"
    }
   },
   "source": [
    "# Write your answer here:\n",
    "print('Madelyn Carlson')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madelyn Carlson\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "    \n",
    "Import the `pandas`, `matplotlib.pyplot`, `numpy`, `scipy` libraries and assign them with proper nicknames."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:24:28.742447Z",
     "start_time": "2025-10-10T12:24:26.819956Z"
    }
   },
   "source": [
    "# Write your answer here:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from scipy.stats import shapiro\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:10:43.898089Z",
     "start_time": "2025-10-10T12:10:43.891642Z"
    }
   },
   "source": [
    "# Do not delete this code section.\n",
    "np.random.seed(100)"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Write a function that output marginal summary statistics and missing values for continuous variable (10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "**Write the function with `def`** (6')\n",
    "- Given a vector of continuous measure, you are asked to write a function named `fn_marginal_continuous`.\n",
    "- The function has one parameter `input_vec` and outputs a list of summary measure and the number of missing values.\n",
    "- Check the missingness of the `input_vec` using `np.isnan()` or `pd.isna()` functions.\n",
    "    - In our first case, we will assume the `input_vec` is an numpy array with missing values marked with `np.nan`.\n",
    "- The list of summary measure can be either **(mean, std)** or **(median, q1, q3)** depending on the normality assumption.\n",
    "    - To determine the normality assumption, you can rely on the p-value of the Shapiro-Wilk test.\n",
    "    - Relevant functions can be found here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html \n",
    "    - If the p-value < 0.05, it is not normally distributed, otherwise, you can treat it as normally distributed.\n",
    "    - Think about what measure to report based on the normality assumption.\n",
    "    - Part of relevant functions can be found here: https://numpy.org/doc/2.0/reference/generated/numpy.nanmean.html\n",
    "- The return statement should include two components: `missing_num` and `output_ls` (your summmary measure).\n",
    "    - The missing numbers should be of type `int` instead of `np.int64`, and summary values should be of type `float` instead of `np.float64`.\n",
    "    - Round all your summary values such that they have no more than **3** digits after the decimals."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:10:46.624184Z",
     "start_time": "2025-10-10T12:10:46.618069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# rite your defined function in this code chunk only.\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "def fn_marginal_continuous(input_vec):\n",
    "    missing_filter = np.isnan(input_vec)\n",
    "    missing_num = int(np.sum(missing_filter)) # How do you check for the amount of missingness?\n",
    "    clean_vec = input_vec[~missing_filter] # Here, I'm removing missing values for the analysis. I'm assuming that I need to do this because I get an error when I run code without it, but let me know if removing missing values isn't necessary\n",
    "\n",
    "    # Check for normality using Shapiro-Wilk\n",
    "    if len(clean_vec) >= 3:  # adding bc Shapiro-Wilk requires at least 3 values\n",
    "        stat, p_value = shapiro(clean_vec)\n",
    "    else:\n",
    "        p_value = 0\n",
    "    # If data is normally distributed, I'll ask for mean and std\n",
    "    if p_value > 0.05:\n",
    "        mean_val = round(float(np.mean(clean_vec)), 3)\n",
    "        std_val = round(float(np.std(clean_vec, ddof=1)), 3)\n",
    "        output_ls = ['mean', mean_val, 'std', std_val]\n",
    "    else:\n",
    "    # If data is not normally distributed, I'll ask for median, q1, and q3\n",
    "        median_val = round(float(np.median(clean_vec)), 3)\n",
    "        q1 = round(float(np.percentile(clean_vec, 25)), 3)\n",
    "        q3 = round(float(np.percentile(clean_vec, 75)), 3)\n",
    "        output_ls = ['median', median_val, 'q1', q1, 'q3', q3]\n",
    "\n",
    "    return missing_num, output_ls"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "**Test your function with the following different arguments:** (4') <br>\n",
    "For each scenario, please export the results as `missing_num_x`, `output_ls_x` and print them out separately.\n",
    "1. A standard normal random vector with a sample size of 100, named `input_vec_1`.\n",
    "2. A Chi-squared random vector with a degree of freedom 1 and a sample size of 100, named `input_vec_2`.\n",
    "3. Change the first element of `input_vec_1` as `np.nan` and create a new array named `input_vec_3`.\n",
    "    - Note that to create a copy of an numpy array, use `np.copy()` first.\n",
    "4. Change the last element of `input_vec_2` as `np.nan` and create a new array named `input_vec_4`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:10:49.561807Z",
     "start_time": "2025-10-10T12:10:49.555563Z"
    }
   },
   "source": [
    "# Write your own code for scenario 1:\n",
    "input_vec_1 = np.random.normal(loc=0, scale=1, size=100)\n",
    "missing_num_1, output_ls_1 = fn_marginal_continuous(input_vec_1)\n",
    "print(\"Missing values:\", missing_num_1)\n",
    "print(\"Summary statistics for scenario 1:\", output_ls_1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: 0\n",
      "Summary statistics for scenario 1: ['mean', -0.104, 'std', 0.975]\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:10:50.886612Z",
     "start_time": "2025-10-10T12:10:50.881517Z"
    }
   },
   "source": [
    "# Write your own code for scenario 2:\n",
    "input_vec_2 = np.random.chisquare(df=1, size=100)\n",
    "missing_num_2, output_ls_2 = fn_marginal_continuous(input_vec_2)\n",
    "print(\"Missing values:\", missing_num_2)\n",
    "print(\"Summary statistics for scenario 2:\", output_ls_2)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: 0\n",
      "Summary statistics for scenario 2: ['median', 0.43, 'q1', 0.089, 'q3', 1.184]\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:10:52.393606Z",
     "start_time": "2025-10-10T12:10:52.386566Z"
    }
   },
   "source": [
    "# Write your own code for scenario 3:\n",
    "input_vec_3 = np.copy(input_vec_1)\n",
    "input_vec_3[0] = np.nan\n",
    "missing_num_3, output_ls_3 = fn_marginal_continuous(input_vec_3)\n",
    "print(\"Missing values:\", missing_num_3)\n",
    "print(\"Summary statistics for scenario 3:\", output_ls_3)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: 1\n",
      "Summary statistics for scenario 3: ['mean', -0.088, 'std', 0.965]\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:11:08.748894Z",
     "start_time": "2025-10-10T12:11:08.737420Z"
    }
   },
   "source": [
    "# Write your own code for scenario 4:\n",
    "input_vec_4 = np.copy(input_vec_2)\n",
    "input_vec_4[-1] = np.nan\n",
    "missing_num_4, output_ls_4 = fn_marginal_continuous(input_vec_4)\n",
    "print(\"Missing values:\", missing_num_4)\n",
    "print(\"Summary statistics for scenario 4:\", output_ls_4)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: 1\n",
      "Summary statistics for scenario 4: ['median', 0.422, 'q1', 0.088, 'q3', 1.19]\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write a function that output marginal summary statistics and missing values for categorical variable (5')\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "**Write the function with `def`**\n",
    "- Given a column vector, you are asked to write a function named `fn_marginal_categorical`.\n",
    "- The function has one parameter named `input_vec` and outputs a list of summary measure and the number of missing values.\n",
    "- Check the missingness of the `input_vec` using `np.isnan()` or `pd.isna()` functions.\n",
    "    - In our second case, we will assume the `input_vec` is a column from a pandas DataFrame with missing values marked with `np.nan`.\n",
    "    - You can use both functions to identify missing values and yield the number of missingness.\n",
    "    - Use `pd.Series.value_counts()` function to obtain the frequency and proportion of `input_vec`, denoted as `tab_count` and `tab_percent`, respectively.\n",
    "    - Details can be found here: https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html\n",
    "    - For proportion, please use percentage (0-100%). You can ignore % when reporting.\n",
    "- The return statement should include two components: `missing_num` and `output_tab` (your summmary measure).\n",
    "    - For your `output_tab`, combine the count and proportion together using `pd.concat()`. Your `output_tab` should have three columns: variable name, count, and proportion.\n",
    "    - Details can be found here: https://pandas.pydata.org/docs/reference/api/pandas.concat.html\n",
    "    - The missing numbers should be of type `int` instead of `np.int64`, and percentgae values should be of type `float` instead of `np.float64`.\n",
    "    - Round all your relevant summary values such that they have no more than **2** digits after the decimals."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:43:21.413671Z",
     "start_time": "2025-10-10T12:43:21.407982Z"
    }
   },
   "source": [
    "# Write your defined function in this code chunk only.\n",
    "def fn_marginal_categorical(input_vec):\n",
    "    series = pd.Series(input_vec)\n",
    "    missing_mask = pd.isna(series)\n",
    "    missing_num = int(missing_mask.sum())\n",
    "    tab_count = series.value_counts(dropna=False)\n",
    "    tab_percent = series.value_counts(normalize=True, dropna=False) * 100\n",
    "    tab_count = tab_count.astype(int)\n",
    "    tab_percent = tab_percent.astype(float).round(2)\n",
    "    output_tab = pd.concat([tab_count, tab_percent], axis=1).reset_index()\n",
    "    output_tab.columns = ['variable', 'count', 'proportion']\n",
    "\n",
    "    return missing_num, output_tab\n"
   ],
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test your written functions with a real dataset. (3')\n",
    "\n",
    "<font size='4'>\n",
    "    \n",
    "**Test the summary function for the continuous measure** (1')\n",
    "- Load the `PTSD dataset.xlsx` and name it as `ptsd_df`.\n",
    "    - The dataset should be stored under `data` folder when you sync changes and fetch origins the GitHub repository.\n",
    "- Use the column `pcl5month_score.baseline` as the input vector. This is a continuous measure.\n",
    "- Extract the corresponding column and give it a name `pcl5month_base`.\n",
    "- (*Optional*) You convert from a pandas.dataframe to an numpy array."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:24:37.205174Z",
     "start_time": "2025-10-10T12:24:36.637536Z"
    }
   },
   "source": [
    "# import ptsd dataset in this code section only (no point for this part as you have done it a few times)\n",
    "ptsd_df = pd.read_excel(\"/Users/madelyncarlson/Documents/GitHub/BIOS-584/data/PTSD dataset.xlsx\", sheet_name=\"main_dataset\")"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:29:51.587431Z",
     "start_time": "2025-10-10T12:29:51.574052Z"
    }
   },
   "source": [
    "# First, I am extracting the column I'll use as the input vector and converting it from a pandas.dataframe to a numpy array\n",
    "pcl5month_base = ptsd_df['pcl5month_score.baseline']\n",
    "pcl5month_base = pcl5month_base.to_numpy()\n",
    "# Use pcl5month_base as the input vector in function I created & print results\n",
    "missing_num, output_tab = fn_marginal_categorical(pcl5month_base)\n",
    "print(\"Missing values:\", missing_num)\n",
    "print(\"Summary table:\\n\", output_tab)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: 9\n",
      "Summary table:\n",
      "     variable  count  proportion\n",
      "0       59.0     21        4.35\n",
      "1       46.0     19        3.93\n",
      "2       58.0     19        3.93\n",
      "3       50.0     18        3.73\n",
      "4       45.0     14        2.90\n",
      "..       ...    ...         ...\n",
      "64      13.0      1        0.21\n",
      "65      18.0      1        0.21\n",
      "66      26.0      1        0.21\n",
      "67      77.0      1        0.21\n",
      "68      17.0      1        0.21\n",
      "\n",
      "[69 rows x 3 columns]\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "**Test the summary function for the categorical measure** (2')\n",
    "\n",
    "- Use the column `mdd_code` as the input vector. This is a binary vector.\n",
    "1. Extract the corresponding column and give it a name `mdd_code_vec`. Output your results as `missing_num_1` and `tab_1`. Print each element out (You will write `print()` twice).\n",
    "2. Create a copy of `mdd_code_vec` and name it as `mdd_code_vec_2`. Change its first element to `NaN`.\n",
    "    - Rerun the `fn_marginal_categorical()` with the new vector. Output your results as `missing_num_2` and `tab_2`. Print each element out (You will write `print()` twice)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:42:48.284086Z",
     "start_time": "2025-10-10T12:42:48.276290Z"
    }
   },
   "source": [
    "# Write your own code for scenario 1 only:\n",
    "mdd_code_vec = ptsd_df['mdd_code']\n",
    "missing_num_1, tab_1 = fn_marginal_categorical(mdd_code_vec)\n",
    "print(\"Missing values for scenario 1:\", missing_num_1)\n",
    "print(\"Summary table:\\n\", tab_1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values for scenario 1: 0\n",
      "Summary table:\n",
      "    variable  count  proportion\n",
      "0         0    340       70.39\n",
      "1         1    143       29.61\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:42:46.556875Z",
     "start_time": "2025-10-10T12:42:46.536858Z"
    }
   },
   "source": [
    "# Write your own code for scenario 2 only:\n",
    "mdd_code_vec_2 = np.copy(mdd_code_vec.to_numpy().astype(float))\n",
    "mdd_code_vec_2[0] = np.nan\n",
    "missing_num_2, tab_2 = fn_marginal_categorical(mdd_code_vec_2)\n",
    "print(\"\\nMissing values for scenario 2:\", missing_num_2)\n",
    "print(\"Summary table:\\n\", tab_2)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values for scenario 2: 1\n",
      "Summary table:\n",
      "    variable  count  proportion\n",
      "0       0.0    339       70.19\n",
      "1       1.0    143       29.61\n",
      "2       NaN      1        0.21\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lambda functions and for loop (2')\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "- Create a ``` lambda ``` function that checks if column `pcl5_score_intake` is greater than 30, denoted as `fn_pcl5_ptsd_check`.\n",
    "- Create a new list `pcl5_score_intake_ls` that shows `True` if `pcl5_score_intake`>30 and `False` otherwise using a for loop.\n",
    "    - You can also try `map()` function to iterate the function over `pcl5_score_intake`.\n",
    "    - Syntax is simple: `map(function_name, iterable, ...)`. \n",
    "- Print out the number of patients with `pcl5_score_intake` over 30 and mark them as **Clinically Significant for PTSD**.\n",
    "    - Your output can be something like `XXX out of YYY patients (ZZZ%) were marked as clinically significant for PTSD.`\n",
    "    - Round your percentage with no more than **2** decimals."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:51:16.777630Z",
     "start_time": "2025-10-10T12:51:16.773820Z"
    }
   },
   "source": [
    "# first, define the lambda function\n",
    "fn_pcl5_ptsd_check = lambda x: x > 30\n",
    "# extract the column\n",
    "pcl5_score_intake = ptsd_df['pcl5_score_intake']\n",
    "pcl5_score_intake_ls = list(map(lambda x: 'true' if fn_pcl5_ptsd_check(x) else 'false', pcl5_score_intake))\n",
    "# count how many are experiencing clinical significant ptsd\n",
    "total_patients = len(pcl5_score_intake_ls)\n",
    "clinically_significant = pcl5_score_intake_ls.count('true')\n",
    "percent_significant = round((clinically_significant / total_patients) * 100, 2)\n",
    "# print the results\n",
    "print(f\"In this dataset, {clinically_significant} out of {total_patients} patients ({percent_significant}%) were marked as clinically significant for PTSD.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this dataset, 451 out of 483 patients (93.37%) were marked as clinically significant for PTSD.\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "45fc1f684f6f416f40889115beff3ddf69879b64cf4bfee48cb72a61e9d15d1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
